# RQueT---Resource-of-Question-Types

## Annotation Guidelines

## Corpus

## Models
We make available the most significant models trained within this work. Specifically, we make available the following:
- the NB model trained on the speaker-after feature (https://drive.google.com/drive/folders/1nLfdbTCf81tA689vuadsBs89gYs8Ry3j?usp=sharing)
- the BERT model fine-tuned on the question and the context-after (https://drive.google.com/drive/folders/1nLfdbTCf81tA689vuadsBs89gYs8Ry3j?usp=sharing)
- the BERT model fine-tuned on the question and the context-before (https://drive.google.com/drive/folders/1nLfdbTCf81tA689vuadsBs89gYs8Ry3j?usp=sharing)
- the BERT model fine-tuned only on the question (https://drive.google.com/drive/folders/1nLfdbTCf81tA689vuadsBs89gYs8Ry3j?usp=sharing)
- the FF model trained on a) the fine-tuned BERT model of question and context-after and b) the speaker-after (found within the folder *models*)
- the SVM model trained on the fine-tuned BERT model of question and context-before (found within the folder *models*)
- the best lexicalized model trained on the bigrams and trigrams of the surface forms and the POS tags of the question, of the first context-before and of the first context-after (found within the folder *models*)
 
