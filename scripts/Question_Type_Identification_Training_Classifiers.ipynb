{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Classifier based on BERT embeddings and other features\n",
    "A version of this notebook was used to train some of the models presented in our paper. All models trained here are based either only on the fine-tuned BERT embeddings extracted as fixed vectors or on the fine-tuned BERT embeddings extracted as fixed vectors and enhanced with the speaker information. The trained models can be found in the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAOuzHgxyEis"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q29vaTI1ysFW"
   },
   "outputs": [],
   "source": [
    "# read in the files with the fine-tuned embeddings\n",
    "df_embeds_train = pd.read_csv(\"fine-tuned_bert_embeddings/fine-tuned_bert_embeds_on_queAndCtxAfter_trainset.csv\", delimiter=',', header=0 )\n",
    "df_embeds_test = pd.read_csv(\"fine-tuned_bert_embeddings/fine-tuned_bert_embeds_on_queAndCtxAfter_testset.csv\", delimiter=',', header=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "LR80GCUFOL36",
    "outputId": "f7de418f-7b29-4dfa-bf4e-1960e1e3191a"
   },
   "outputs": [],
   "source": [
    "# make sure that the file is read in the way it should\n",
    "df_embeds_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "tspd5FpFysKm",
    "outputId": "7fd72c17-91b6-4f7f-f7f7-842cef0b888b"
   },
   "outputs": [],
   "source": [
    "# read in the files containing the extra features for each question\n",
    "# here: the speaker before and after information\n",
    "train_df = pd.read_csv(\"simple_features_annotations/rquet_trainset_simple_features.csv\", delimiter='\\t', header=0 )\n",
    "test_df = pd.read_csv(\"simple_features_annotations/rquet_testset_simple_features.csv\", delimiter='\\t', header=0 )\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "id": "0cgaKP8MO-2Y",
    "outputId": "c6f8aa06-c534-4e4e-cacf-5896e3b15c5f"
   },
   "outputs": [],
   "source": [
    "# merge the simple features with the bert embeddings dataframe\n",
    "merged_df_train = pd.merge(train_df, df_embeds_train, on='ID')\n",
    "merged_df_test = pd.merge(test_df,df_embeds_test, on='ID')\n",
    "merged_df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBOREv8DQSQV"
   },
   "outputs": [],
   "source": [
    "# feature selection: The all_feats list contains the speaker feature and the fine-tuned bert embeddings. In this list,\n",
    "# you can modify the specific speaker feature you want to train on: if you want to train on the speaker-after feature,\n",
    "# you need to use index 2; if you want to train on the speaker-before feature, you need to use index 3\n",
    "# The bert_feats list contains only the fine-tuned bert embeddings.  \n",
    "all_feats = np.r_[2, 4:772]\n",
    "bert_feats = np.r_[2:772]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdVRuvy9C0OH",
    "outputId": "6810b65a-b6ac-4071-93b6-91ae566a2819"
   },
   "outputs": [],
   "source": [
    "# If you want to train only on the bert embeddings, use the bert_feats list. If you want to \n",
    "# train on bert plus the speaker information, use the all_feats list.\n",
    "X_train = merged_df_train.values[0:, all_feats].astype(\"float32\")\n",
    "Y_train = merged_df_train.values[0:,1].astype(\"float32\")\n",
    "X_test = merged_df_test.values[0:, all_feats].astype(\"float32\")\n",
    "Y_test = merged_df_test.values[0:,1].astype(\"float32\")\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPumtQj9H9I9"
   },
   "outputs": [],
   "source": [
    "# import classifiers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn import metrics \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "otEzi-CfC0TQ",
    "outputId": "cf4f4efe-87de-4b4c-ca84-df1852bf1a33"
   },
   "outputs": [],
   "source": [
    "#### Gaussian\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_gaus_test = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_pred_gaus_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9ZULgXtC0V2",
    "outputId": "2ca4f835-ed5b-4ed4-9680-d9bdb10c58fb"
   },
   "outputs": [],
   "source": [
    "### SVM \n",
    "\n",
    "svm_final = svm.SVC(C=10, gamma= 'scale', kernel='rbf')\n",
    "svm_final.fit(X_train, Y_train)\n",
    "\n",
    "y_pred_svm_test = svm_final.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_pred_svm_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDjWaNmzHh6H",
    "outputId": "0f512007-f448-4422-f928-8a7fa0c10eb3"
   },
   "outputs": [],
   "source": [
    "### MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_mlp = MLPClassifier(hidden_layer_sizes=(7,), #\n",
    "                                       activation='relu',\n",
    "                                       solver='adam',\n",
    "                                       learning_rate='adaptive',\n",
    "                                       max_iter=1000,\n",
    "                                       learning_rate_init=0.01,\n",
    "                                       alpha=0.01)\n",
    "model_mlp.fit(X_train, Y_train)\n",
    "y_pred_mlp_test = model_mlp.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_pred_mlp_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvqaepGVHh8z",
    "outputId": "a432a777-a04d-44a8-9f80-e47012bc5cfc"
   },
   "outputs": [],
   "source": [
    "### decision tree\n",
    "clf_gini = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = 5)\n",
    "clf_gini.fit(X_train, Y_train) \n",
    "\n",
    "y_pred_test = clf_gini.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8scMahv9Hh_i",
    "outputId": "0ef4ba80-0dd1-4bc9-d4cb-00546e124599"
   },
   "outputs": [],
   "source": [
    "### FF neural net\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "# depending on whether you trained on all the features or only the bert embeddings, uncomment the following lines\n",
    "in_shape = len(all_feats)\n",
    "#in_shape = len(bert_feats)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(in_shape,))) \n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train,\n",
    "Y_train,\n",
    "epochs=3, \n",
    "batch_size=32, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(X_test.astype(\"float32\"), Y_test.astype(\"float32\"), verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ShkLyxYHiDe",
    "outputId": "b1c3ffa2-9553-4b38-985d-f902c763e66d"
   },
   "outputs": [],
   "source": [
    "### LSTM\n",
    "\n",
    "# depending on whether you trained on all the features or only the bert embeddings, uncomment the following lines\n",
    "in_shape = len(all_feats)\n",
    "#in_shape = len(bert_feats)\n",
    "\n",
    "\n",
    "reshaped_X = X_train.reshape((1588, 1, in_shape)) \n",
    "reshaped_X_test = X_test.reshape((180, 1, in_shape))\n",
    "\n",
    "rnn = Sequential()\n",
    "rnn.add(layers.LSTM(200, return_sequences=True))\n",
    "rnn.add(layers.LSTM(100))\n",
    "rnn.add(Dense(1, activation='sigmoid'))\n",
    "rnn.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = rnn.fit(reshaped_X.astype(\"float32\"), Y_train.astype(\"float32\"),\n",
    "epochs=10,\n",
    "batch_size=32,\n",
    "validation_split=0.2)\n",
    "\n",
    "\n",
    "score = rnn.evaluate(reshaped_X_test.astype(\"float32\"), Y_test.astype(\"float32\"), verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lGt4rRIrysO4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Question Identification Task - Enhancing Fine-tuned BERT.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
